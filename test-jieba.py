#!/usr/bin/env python3

import csv
import jieba
import demoji
import re
from lxml.html import fromstring


# å‰µå»ºåœç”¨è©list
def stopwords_list(filepath: str) -> list:
    stopwords = [
        line.strip()
        for line in open(filepath, "r", encoding="utf-8").readlines()
    ]
    return stopwords


def concat_sentance(row: list) -> str:
    sentance = ""
    for i in range(0, 2):
        if row[i] != "NULL":
            sentance += row[i].strip()
    return sentance


def remove_emojii(sentance: str) -> str:
    # å»é™¤ emojii
    demoji_sentence = demoji.replace(sentance, "")
    return demoji_sentence


def remove_htmltag(sentance: str) -> str:
    # ç§»é™¤ HTML tag
    notag_sentance = fromstring(sentance).text_content()
    # print(notag_sentance)
    return notag_sentance


def remove_link(sentance: str) -> str:
    # ç§»é™¤ http, https url é€£çµ
    nolink_sentance = re.sub(r"http[s]?://\S+", "", sentance)
    # print(nolink_sentance)
    return nolink_sentance


def remove_stopword(stopword_list: list, seged_list: list) -> list:
    proced_sentence = []
    for seged_word in seged_list:
        if seged_word not in stopword_list and seged_word != " ":
            proced_sentence.append(seged_word)
    return proced_sentence


if __name__ == "__main__":
    # my_string = """ã€ç¯€ç›®å¿«è¨Šã€‘é€±äº”ç¾é£Ÿå–®å…ƒï¼šå§šèˆœæ™‚é–“ å¿«è·Ÿè‘—å¸¥å“¥ç¾é£Ÿé”äººå§šèˆœä¸€èµ·åƒå–ç©æ¨‚å§ï¼ï¼ ä»Šå¤©ç•¶ç„¶è¦ä¾†èŠèŠã€Šè‡ºåŒ—ã€è‡ºä¸­ã€è‡ºå—& é«˜é›„ç±³å…¶æ—æŒ‡å—2022ã€‹ æŒ‰è®šè¿½è¹¤ å§šèˆœ & å§šèˆœç¾é£Ÿä¸­å¤®ç¤¾ Facebookï¼ŒæŒæ¡æœ€æ–°æœ€å¿«çš„ç¾é£Ÿè³‡è¨Šï¼ ğŸ“»è½é‡æ’­æŒ‰é€™è£¡ï¼https://youtu.be/VzYUIPo-BiE â–¶é£›ç¢Ÿè¯æ’­ç¶²Youtubeã€Šé£›ç¢Ÿæ—©é¤ã€‹é »é“ http://bit.ly/2QVQsFh â–¶ç¶²è·¯ç·šä¸Šæ”¶è½ http://www.uforadio.com.tw/stream/stream.html â–¶ é£›ç¢ŸAPPï¼Œè®“ä½ æ”¶è½é›¶è·é›¢ IOSï¼šhttps://reurl.cc/3jYQMV Androidï¼šhttps://reurl.cc/5GpNbR â–¶ é£›ç¢ŸPodcast SoundOn : https://bit.ly/30Ia8Ti Apple Podcasts : https://apple.co/3jFpP6x Spotify : https://spoti.fi/2CPzneD Google æ’­å®¢ï¼šhttps://bit.ly/3gCTb3G KKBOXï¼šhttps://reurl.cc/MZR0K4"""
    data_proc_file = "data/p48_posts.csv"
    output_file = "outfile/p48_posts.csv"

    # ä¿®æ”¹é è¨­è©å…¸
    jieba.set_dictionary("dict/dict.txt.big")
    # è¼‰å…¥è‡ªå®šç¾©è©å…¸
    jieba.load_userdict("dict/user_dict.txt")
    # è¼‰å…¥åœç”¨å­—
    stopwords = stopwords_list("dict/stop_words_zh.txt")
    # æº–å‚™å¯«å…¥æª”æ¡ˆçš„ list
    proced_sentence_list = list()

    # é–‹å•Ÿ CSV æª”æ¡ˆ
    with open(data_proc_file, newline="") as csvfile:
        # è®€å– CSV æª”æ¡ˆå…§å®¹
        rows = csv.reader(csvfile)

        # ä»¥è¿´åœˆè¼¸å‡ºæ¯ä¸€åˆ—
        # i = 1
        for row in rows:
            # if i > 10:
            #     break
            orig_sentance = concat_sentance(row)
            # ç§»é™¤ emojii
            demoji_sentence = remove_emojii(orig_sentance)
            # å¦‚æœç¨‹åºè™•ç†å®Œè®Šæˆç©ºå­—ä¸²å‰‡ç›´æ¥è·³é
            if len(demoji_sentence) == 0:
                continue
            # ç§»é™¤ HTML Tag
            notag_sentance = remove_htmltag(demoji_sentence)
            # ç§»é™¤ http, https url é€£çµ
            nolink_sentance = remove_link(notag_sentance)
            seged_sentence = jieba.lcut(
                nolink_sentance, cut_all=False, HMM=True
            )
            proced_sentence = remove_stopword(stopwords, seged_sentence)

            proced_sentence_list.append(proced_sentence)

            print("|".join(proced_sentence))

            # i += 1

    with open(output_file, "w", newline="") as writefile:
        # å»ºç«‹ CSV æª”å¯«å…¥å™¨
        writer = csv.writer(writefile)
        for write_sentance in proced_sentence_list:
            writer.writerow([" ".join(write_sentance)])
